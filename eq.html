<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <title>three.js Graphic EQ</title>
    <style>
        body {
            /* set margin to 0 and overflow to hidden, to go fullscreen */
            margin: 0;
            overflow: hidden;
        }
        div#mp3_player{ width:500px; height:60px; background:#000; padding:5px; margin:50px auto; }
        div#mp3_player > div > audio{  width:500px; background:#000; float:left;  }
        div#mp3_player > canvas{ width:500px; height:30px; background:#002D3C; float:left; }
        div#container > canvas{ width:800px; height:600px; background:#ffffff; float:left; }
    </style>
</head>

<body>
    <script src="docs/libraries/three.js"></script>
    <script src="docs/libraries/OrbitControls.js"></script>
    <script src="docs/libraries/stats.js"></script>

    <div id="container">
    <div id="mp3_player">
    <div id="audio_box">
    </div>


<script type="text/javascript">
/*** base Graphic EQ code by srchea  */

var camera, scene, renderer;
var controls;
var listener;
var document;
var audio = new Audio();

// Establish all variables that your Analyser will use
var source, context, analyser, analysisCtx, dataArray, bufferLength, v;

scene = new THREE.Scene();

function audioElement(){
    // Create a new instance of an audio object and adjust some of its properties
    //audio.src = "file:///home/tagp/gustable.github.io/docs/CutYourHair.mp3";
    audio.src = "docs/00 - Cut Your Hair.mp3";
    audio.controls = true;
    audio.loop = true;
    audio.autoplay = true;

    context = new (window.AudioContext || window.webkitAudioContext)();
    analyser = context.createAnalyser(); // AnalyserNode method
    analyser.fftSize = 32;

    // Re-route audio playback into the processing graph of the AudioContext
    source = context.createMediaElementSource(audio); 
    source.connect(analyser);
    analyser.connect(context.destination);
    return analyser;
}

function freqData(m, analysisCtx){
    var bufferLength = analysisCtx.frequencyBinCount;
    var dataArray = new Uint8Array(bufferLength);
    analyser.getByteTimeDomainData(dataArray);
    var v = dataArray[m];
    console.log(v*0.1);
    return v;
}

function setRect(n){    
        var geometry = new THREE.CubeGeometry(1, freqData(n, analysisCtx)*0.1, 1);
        var material = new THREE.MeshBasicMaterial({
            color: 0x7777f});
        var rect = new THREE.Mesh(geometry, material);
        rect.name = "rect-" + scene.children.length;
        rect.translateZ(n * 2.5);
        scene.add(rect);
}

function init() {
    camera = new THREE.PerspectiveCamera( 50, window.innerWidth / window.innerHeight, 1, 100 );
    camera.position.set( 50, 50, 50 );
    
    // create an AudioListener and add it to the camera
    listener = new THREE.AudioListener();
    camera.add( listener );

    analysisCtx = audioElement();

    renderer = new THREE.WebGLRenderer();
    renderer.setSize( window.innerWidth, window.innerHeight );

    // show cubes in an array
    var i;
    for(i=0; i<10; i++) {
        setRect(i, analysisCtx);
    }

    // show axes in the screen
    var axes = new THREE.AxesHelper(2);
    scene.add(axes);

    var ambientLight = new THREE.AmbientLight(0x7777ff);
    scene.add(ambientLight);

    controls = new THREE.OrbitControls(camera);
    controls.rotateSpeed = 4;
}

init();
controls.update();
renderer.render(scene, camera);
animate();

function animate() {
    var l;
    for(l=0; l<10; l++) {
        freqData(l, analysisCtx);
        setRect(l);
    }
    requestAnimationFrame( animate );
    controls.update();
    renderer.render( scene, camera );
}

document.getElementById('audio_box').appendChild(audio);
document.getElementById('container').appendChild(renderer.domElement);


</script>

</div>
</body>
</html>